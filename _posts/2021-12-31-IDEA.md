---
layout:     post
title:      IDEA
subtitle:   IDEA 开发的 spark + maven 项目
date:       2021-12-31
author:     果然
header-img: img/timg.jpg
catalog: true
tags:
    - IDEA
---


因为在内网开发和使用大数据中心远程服务资源的缘故，所以将spark开发过程记录下来，以便参考。

首先选用 idea 进行开发。idea的安装与激活过程，这里不在赘述;对scala代码/java 代码进行打包编译时，可以使用maven，也可以使用 sbt。这里，使用maven。

相关项目管理工具软件等版本对应下载：  
```
idea：2021.1.1
maven：(apache-maven)3.5.0
java：1.8.0_301
scala: 2.11.8
scala 的idea 插件：scala-intellij-bin-2021.1.22.zip
```

## 1. [理解 maven 是干嘛的？](https://www.zhihu.com/question/20104186)  
Apache maven是一个(特别是java编程)项目管理及自动构建工具，基于项目对象模型(POM)，maven利用一个中央信息片段能管理一个项目的构建、报告和文档等步骤。

## 2. [spark + Maven](https://blog.csdn.net/sp_ur/article/details/82683264)
下面搭建 spark + maven ，编写 spark 应用程序，maven用于进行打包操作。  

穿插小知识点：
```
GroupID 是项目组织唯一的标识符，实际对应 JAVA 的包结构。  
一般分为多段，第一段为域，第二段为公司名称。
域又分为 org、com、cn等等。其中 org为非营利组织，com 为商业组织。如：org.apache.
ArtifactID 是项目名称，如 Apache的tomcat项目。
```

## 3. [Maven 配置](https://blog.csdn.net/yup1212/article/details/81631030)  
以下对 maven进行配置并对默认配置进行修改默认 repository。  

setting.xml 是用来设置 maven 参数的配置文件，并且是 **maven 的全局配置文件**。参考内网镜像和大数据中心仓库地址，添加如下设置：
```
<mirror>
<id>greeMavenMirror<id>
<mirrorof>*</mirrorof>
<name>gree maven mirror</name>
<url>http://xxx/repository/maven-public/</url>
</mirror>
```  

## 4. [scala 插件](https://blog.csdn.net/weixin_42081778/article/details/100079899)
配置scala的idea插件，解决idea右键无法 new 出 scala 问题：

## 5. [hive 查询数据](https://blog.csdn.net/chenbetter1996/article/details/80441178?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-8.essearch_pc_relevant&spm=1001.2101.3001.4242.5)
配置并搭建好 maven 项目后，spark 连接远程 hive 查询数据。
搭建一个单元测试代码：查询数据库、数据库表

因为远程服务添加了 kerberos 网络授权协议，需在代码中设置：
```
System.setProperty("java.security.krb5.conf", krb5);
System.setProperty("javax.security.auth.useSubjectCredsOnly", "false");
Configuration configuration = new Configuration();
UserGroupInformation.setConfiguration(configuration);
UserGroupInformation.loginUserFromKeytab(user, keytab);
```
**kerberos** 是一种计算机网络授权协议，用来在非安全网络中，对个人通信以安全的手段进行身份认证。
		
不做其他操作，可能出现以下几个问题：
### 5.1  [（Hadoop）HADOOP_HOME and hadoop.home.dir are unset.](https://www.jianshu.com/p/a65a95108620)

**总结**：本地开发hadoop/spark等程序时，需在本地安装 hadoop，对应的bin下需有 winutils.exe。  
          否则，需在 **https://github.com/steveloughran/winutils** 中下载指定版本或相近版本，替代 bin目录。

### 5.2 [Windows 上 org.apache.spark.sql.AnalysisException: java.lang.RuntimeException: The root scratch dir: /tmp/hive on HDFS should be writable. Current permissions are: rwx------;](https://www.cnblogs.com/hecxx/p/11959835.html)  

**总结**：添加路径权限

### 5.3 仅显示 default 数据库
在 main/resources 中添加 对应的 core-site.xml、mapred-site.xml、hdfs-site.xml、yarn-site.xml与jks认证。

### 5.4 caused by: javax.security.auth.lofin.LoginException create breakpoint: cdh-master01
在 hosts 中添加 域名与ip 地址对应关系

